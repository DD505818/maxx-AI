version: '3.9'
models:
  llama3:
    image: ghcr.io/vllm/vllm-engine:2.0
    resources:
      reservations:
        devices:
          - capabilities: [gpu]
services:
  redpanda:
    image: redpandadata/redpanda:v23.2
    command: start --mode dev-container
    ports:
      - '9092:9092'
  risingwave:
    image: risingwavelabs/risingwave:1.7
    ports:
      - '4567:4567'
  orchestrator:
    build:
      context: ../../backend
      dockerfile: Dockerfile
    env_file: ../../.env
    depends_on:
      - llama3
      - redpanda
    healthcheck:
      test: ['CMD','curl','-f','http://localhost:8080/healthz']
      interval: 30s
      retries: 3
  backend:
    build: ../../backend
    env_file: ../../.env
    environment:
      ORCH_URL: http://orchestrator:8080
    depends_on:
      - orchestrator
      - redpanda
      - risingwave
    ports:
      - '8000:8000'
  frontend:
    build: ../../frontend
    env_file: ../../.env
    environment:
      NEXT_PUBLIC_WS_URL: ws://localhost:8000/ws/agents
    depends_on:
      - backend
    ports:
      - '3000:3000'
